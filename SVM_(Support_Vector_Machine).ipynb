{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOOrtaon7kMmyelaBqzip1v",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/RaymundoDLC/MachineLearning/blob/main/SVM_(Support_Vector_Machine).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OVLnn3QqpGMJ"
      },
      "outputs": [],
      "source": [
        "# ==============================================================================\n",
        "# PROYECTO INTEGRADOR: MODELO SVM (SUPPORT VECTOR MACHINE)\n",
        "# ==============================================================================\n",
        "\n",
        "# --- 1. CONFIGURACIÓN E IMPORTACIONES ---\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.svm import SVC # Modelo clave para SVM\n",
        "from sklearn.metrics import (\n",
        "    classification_report,\n",
        "    confusion_matrix,\n",
        "    recall_score,\n",
        "    roc_curve,\n",
        "    roc_auc_score\n",
        ")\n",
        "\n",
        "# Configuración de visualización\n",
        "pd.set_option('display.max_columns', None)\n",
        "\n",
        "# --- 2. CARGA Y PREPROCESAMIENTO DE DATOS (REUSO DE LA PARTE 1) ---\n",
        "\n",
        "# *NOTA: Asumimos que el archivo .csv ha sido subido.*\n",
        "try:\n",
        "    df = pd.read_csv('lending_club_2007_2011_6_states (1).csv')\n",
        "except FileNotFoundError:\n",
        "    print(\"Error: Asegúrate de subir el archivo CSV al entorno de Colab.\")\n",
        "    exit()\n",
        "\n",
        "# 2.1 Limpieza y creación de la variable objetivo\n",
        "df['repaid'] = df['loan_status'].apply(lambda status: 1 if status in ['Fully Paid'] else 0)\n",
        "\n",
        "# 2.2 Selección, limpieza y Codificación\n",
        "feature_cols = [\n",
        "    'loan_amnt', 'int_rate', 'annual_inc', 'dti', 'delinq_2yrs', 'open_acc',\n",
        "    'pub_rec', 'revol_bal', 'revol_util', 'total_acc',\n",
        "    'purpose', 'grade', 'home_ownership', 'verification_status'\n",
        "]\n",
        "df_clean = df[df.columns.intersection(feature_cols + ['repaid'])].copy()\n",
        "df_clean.dropna(inplace=True)\n",
        "\n",
        "# Codificación One-Hot\n",
        "df_dummies = pd.get_dummies(df_clean, columns=['purpose', 'home_ownership', 'verification_status'], drop_first=True)\n",
        "\n",
        "# Codificación Ordinal de 'grade'\n",
        "grade_mapping = {'A': 7, 'B': 6, 'C': 5, 'D': 4, 'E': 3, 'F': 2, 'G': 1}\n",
        "df_dummies['grade_code'] = df_dummies['grade'].map(grade_mapping)\n",
        "df_dummies.drop('grade', axis=1, inplace=True)\n",
        "\n",
        "# Definición final de X e Y\n",
        "X = df_dummies.drop('repaid', axis=1)\n",
        "y = df_dummies['repaid']\n",
        "\n",
        "# 2.3 División y Escalamiento\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=42, stratify=y)\n",
        "scaler = StandardScaler()\n",
        "numerical_cols = X_train.select_dtypes(include=np.number).columns.tolist()\n",
        "\n",
        "# El escalamiento es **OBLIGATORIO** para SVM.\n",
        "X_train_scaled = X_train.copy()\n",
        "X_test_scaled = X_test.copy()\n",
        "\n",
        "X_train_scaled[numerical_cols] = scaler.fit_transform(X_train[numerical_cols])\n",
        "X_test_scaled[numerical_cols] = scaler.transform(X_test[numerical_cols])\n",
        "\n",
        "\n",
        "# --- 3. ENTRENAMIENTO DEL MODELO SVM (PARTE 2) ---\n",
        "\n",
        "# Se utilizan los hiperparámetros óptimos encontrados en el notebook 'SVM.ipynb'\n",
        "# C=1, kernel='rbf', degree=2.\n",
        "# Se añade probability=True para poder usar predict_proba (necesario para la curva ROC).\n",
        "# Se añade class_weight='balanced' para enfocarse en la clase minoritaria (0: No Pagado).\n",
        "svm_model = SVC(\n",
        "    C=1,\n",
        "    kernel='rbf',\n",
        "    degree=2,\n",
        "    gamma='auto', # Usar el gamma reportado como óptimo\n",
        "    class_weight='balanced',\n",
        "    probability=True, # Necesario para predict_proba() y la curva ROC\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "svm_model.fit(X_train_scaled, y_train)\n",
        "\n",
        "# Predicción de CLASES\n",
        "y_pred = svm_model.predict(X_test_scaled)\n",
        "\n",
        "# Predicción de PROBABILIDADES\n",
        "y_proba = svm_model.predict_proba(X_test_scaled)[:, 1] # Probabilidad de la Clase 1 (Pagado)\n",
        "\n",
        "\n",
        "# --- 4. EVALUACIÓN Y GRÁFICOS (PARTE 3) ---\n",
        "\n",
        "print(\"\\n\" + \"=\"*50)\n",
        "print(\"  REPORTE DE CLASIFICACIÓN (SVM OPTIMIZADO)\")\n",
        "print(\"=\"*50)\n",
        "\n",
        "# 4.1 Reporte de Clasificación y Matriz de Confusión\n",
        "print(classification_report(y_test, y_pred, target_names=['No Pagado (0)', 'Pagado (1)']))\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "print(\"Matriz de Confusión:\\n\", cm)\n",
        "\n",
        "# Métrica de Negocio Clave\n",
        "recall_clase_0 = recall_score(y_test, y_pred, pos_label=0)\n",
        "print(f\"\\nRecall de la Clase 'No Pagado' (0): {recall_clase_0:.4f} (Objetivo de Negocio)\")\n",
        "print(\"-\" * 50)\n",
        "\n",
        "# 4.2 Métricas ROC y AUC\n",
        "auc_score = roc_auc_score(y_test, y_proba)\n",
        "print(f\"Área Bajo la Curva (AUC): {auc_score:.4f}\")\n",
        "\n",
        "# 4.3 Gráfico de la Matriz de Confusión\n",
        "plt.figure(figsize=(6, 5))\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Reds', cbar=False,\n",
        "            xticklabels=['No Pagado (0)', 'Pagado (1)'],\n",
        "            yticklabels=['No Pagado (0)', 'Pagado (1)'])\n",
        "plt.ylabel('Valor Real')\n",
        "plt.xlabel('Predicción')\n",
        "plt.title('Matriz de Confusión (SVM)')\n",
        "plt.show()\n",
        "\n",
        "# 4.4 Generación del Gráfico de Curva ROC\n",
        "fpr, tpr, thresholds = roc_curve(y_test, y_proba)\n",
        "\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.plot(fpr, tpr, color='darkred', lw=2, label=f'Curva ROC (AUC = {auc_score:.4f})')\n",
        "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--', label='Línea Base (0.5)')\n",
        "\n",
        "plt.xlim([0.0, 1.0])\n",
        "plt.ylim([0.0, 1.05])\n",
        "plt.xlabel('Tasa de Falsos Positivos (FPR)')\n",
        "plt.ylabel('Tasa de Verdaderos Positivos (TPR) / Recall')\n",
        "plt.title('Curva ROC para el Modelo SVM')\n",
        "plt.legend(loc=\"lower right\")\n",
        "plt.grid(True)\n",
        "plt.show()"
      ]
    }
  ]
}